<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Análise de Dados sobre o Pedágio da Terceira Ponte | Pedro Moreno | Analista de Dados</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600&family=Source+Sans+Pro:wght@300;400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/style.css">
</head>
<body>
    <header class="site-header">
    <nav class="navigation-menu">
        <a href="/" class="nav-logo">PM.</a> <ul class="nav-links">
            <li><a href="/">Início</a></li>
            <li><a href="/portfolio/">Portfólio</a></li>
            <li><a href="/blog/">Blog</a></li>
            <li><a href="/sobre/">Sobre</a></li>
            <li><a href="/contato/">Contato</a></li>
        </ul>
    </nav>
</header>

    <main class="main-content">
        <article class="page-container">
    
    
    <div class="post-hero-image">
        <img src="/assets/images/thumbs/pic03.jpg" alt="Imagem de cabeçalho para o post Análise de Dados sobre o Pedágio da Terceira Ponte">
    </div>
    
    
    <header class="post-header">
        <h1 class="page-title">Análise de Dados sobre o Pedágio da Terceira Ponte</h1>
        
        <p class="post-meta">Publicado em 17 de junho de 2025</p>
        
        
            <p class="page-intro">Webscrapper feito em Python e Dashboard feito no Tableau Public para analisar os dados do pedágio.</p>
        

        
            <div class="post-tags">
                
                    <span class="tag-chip">Web Scraping</span>
                
                    <span class="tag-chip">Python</span>
                
                    <span class="tag-chip">Tableau</span>
                
                    <span class="tag-chip">Análise de Dados</span>
                
            </div>
        
    </header>

    <div class="post-content">
        <p>Este projeto é uma análise completa dos dados públicos sobre o pedágio da Terceira Ponte, um marco importante aqui em Vila Velha.</p>
<p>O trabalho foi dividido em duas grandes etapas:</p>
<ol>
<li><strong>Web Scraping:</strong> Desenvolvimento de um script em Python para extrair automaticamente os dados de fontes online.</li>
<li><strong>Visualização:</strong> Criação de um dashboard interativo no Tableau Public para apresentar as descobertas de forma visual e intuitiva.</li>
</ol>
<h3>Link</h3>
<ul>
<li><strong><a href="https://public.tableau.com/views/TerceiraPonte/OpedgiodaTerceiraPonteemNmeros?:language=pt-BR&amp;publish=yes&amp;:display_count=n&amp;:origin=viz_share_link">Veja a Análise no Tableau Public</a></strong></li>
<li><strong><a href="https://github.com/Pedrobeats/Projeto3ponte">Ver o Código no GitHub</a></strong></li>
</ul>
<h3>Metodologia</h3>
<p>Este código é uma ferramenta de web scraping escrita em Python que coleta, processa e limpa dados de tráfego da Terceira Ponte no estado do Espírito Santo, Brasil.</p>
<p>O código usa a biblioteca pandas para gerenciar e manipular os dados coletados, e a biblioteca requests para realizar solicitações HTTP e obter o código-fonte HTML da página de dados abertos do governo do Espírito Santo. A biblioteca BeautifulSoup é usada para fazer o parsing do HTML e encontrar os links de download dos arquivos CSV.</p>
<p>O script passa por três funções principais: pegar_links_csv(), importando_csv_pandas() e data_datetime().</p>
<p>A função pegar_links_csv() usa BeautifulSoup para encontrar os links de download dos arquivos CSV e adicioná-los a uma lista. A função importando_csv_pandas() usa a lista de links para baixar cada arquivo CSV e adicioná-lo a um DataFrame do pandas. A função data_datetime() converte a coluna de data/hora para o tipo de dados datetime do pandas, renomeia algumas colunas e faz outras limpezas nos dados. A função exportar_csv() é responsável por exportar o DataFrame final como um arquivo CSV chamado &quot;dados_3ponte.csv&quot;.</p>
<p>No final, o script é executado chamando a função scrapper_3ponte(), que chama as funções acima e salva o arquivo CSV com os dados coletados.</p>
<p>O projeto de DataViz (visualização de dados) feito no Tableau e disponível neste link é uma representação visual dos dados obtidos por meio do código em Python apresentado anteriormente.</p>
<p>A visualização tem como objetivo fornecer uma visão mais clara e acessível dos dados relacionados ao fluxo de veículos na Terceira Ponte, localizada no estado do Espírito Santo. Por meio de gráficos e tabelas interativas, é possível analisar diversos aspectos desse fluxo, como o número de veículos que circulam pela ponte em cada dia da semana, o horário de pico de circulação, a proporção de veículos de cada categoria que trafegam na ponte, entre outros.</p>
<p>Além disso, a visualização permite que o usuário faça suas próprias análises e extraia insights relevantes sobre o fluxo de veículos na Terceira Ponte. Por exemplo, é possível identificar se há um aumento ou diminuição significativa no fluxo de veículos em determinado período do ano, ou se a proporção de veículos de uma determinada categoria mudou ao longo do tempo.</p>
<p>Em resumo, o projeto de DataViz apresentado no Tableau é uma maneira poderosa e eficaz de explorar e visualizar os dados obtidos por meio do código em Python, permitindo uma análise mais profunda e informada do fluxo de veículos na Terceira Ponte.Descreva as bibliotecas Python que você usou para o web scraping (como BeautifulSoup ou Scrapy), como você limpou e tratou os dados e quais foram os principais insights que você descobriu ao visualizar os dados no Tableau.</p>

    </div>

</article>
    </main>

    <footer class="site-footer">
    <p>© 2025 Pedro Moreno. Todos os direitos reservados.</p>
    <p>
        <a href="http://www.linkedin.com/in/pmbsantanna">LinkedIn</a> &bull; 
        <a href="https://github.com/Pedrobeats">GitHub</a>
    </p>
</footer>
</body>
</html>